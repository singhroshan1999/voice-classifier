{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:38px;color:green\"><u>Human Voice classifier</u></div><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#importing data\n",
    "def bytes_from_file(filename, chunksize=8192):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunksize)\n",
    "            if chunk:\n",
    "                for b in chunk:\n",
    "                    yield b\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "datArr1 = np.array([x for x in bytes_from_file('anuragD30.raw')])\n",
    "datArr2 = np.array([x for x in bytes_from_file('anupamD30.raw')])\n",
    "\n",
    "datArr = np.concatenate((datArr1,datArr2))\n",
    "\n",
    "datArr = datArr.reshape((datArr.size//882,882),order = 'C')\n",
    "datY = np.concatenate((np.zeros((1500),dtype = int),np.ones((1500),dtype = int)))\n",
    "x = pd.DataFrame(datArr)\n",
    "y = pd.DataFrame(datY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=882, units=80, kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "e:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "e:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# initializing ANN\n",
    "classifier = Sequential()\n",
    "# adding input and hidden layers\n",
    "classifier.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 882))  # first hidded layer\n",
    "classifier.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))  # second hidded layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))  # output layer\n",
    "# compiling ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2700/2700 [==============================] - 1s 386us/step - loss: 0.5695 - acc: 0.7570\n",
      "Epoch 2/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.2636 - acc: 0.9167\n",
      "Epoch 3/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.1956 - acc: 0.9419\n",
      "Epoch 4/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.1710 - acc: 0.9530\n",
      "Epoch 5/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.1506 - acc: 0.9611\n",
      "Epoch 6/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.1312 - acc: 0.9659\n",
      "Epoch 7/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.1229 - acc: 0.9685\n",
      "Epoch 8/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.1105 - acc: 0.9741\n",
      "Epoch 9/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.1016 - acc: 0.9759\n",
      "Epoch 10/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0918 - acc: 0.9774\n",
      "Epoch 11/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.0849 - acc: 0.9804\n",
      "Epoch 12/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0803 - acc: 0.9811\n",
      "Epoch 13/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0786 - acc: 0.9800\n",
      "Epoch 14/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.1006 - acc: 0.9685\n",
      "Epoch 15/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0950 - acc: 0.9726\n",
      "Epoch 16/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.1073 - acc: 0.9644\n",
      "Epoch 17/100\n",
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.0837 - acc: 0.9741\n",
      "Epoch 18/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0661 - acc: 0.9800\n",
      "Epoch 19/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0564 - acc: 0.9826\n",
      "Epoch 20/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.0488 - acc: 0.9852\n",
      "Epoch 21/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.0430 - acc: 0.9863\n",
      "Epoch 22/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0377 - acc: 0.9896\n",
      "Epoch 23/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.0357 - acc: 0.9896\n",
      "Epoch 24/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0364 - acc: 0.9881\n",
      "Epoch 25/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0313 - acc: 0.9915\n",
      "Epoch 26/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0289 - acc: 0.9922\n",
      "Epoch 27/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0257 - acc: 0.9922\n",
      "Epoch 28/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.0252 - acc: 0.9933\n",
      "Epoch 29/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.0261 - acc: 0.9930\n",
      "Epoch 30/100\n",
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.0249 - acc: 0.9926\n",
      "Epoch 31/100\n",
      "2700/2700 [==============================] - 0s 69us/step - loss: 0.0223 - acc: 0.9948\n",
      "Epoch 32/100\n",
      "2700/2700 [==============================] - 0s 64us/step - loss: 0.0222 - acc: 0.9930\n",
      "Epoch 33/100\n",
      "2700/2700 [==============================] - 0s 60us/step - loss: 0.0189 - acc: 0.9956\n",
      "Epoch 34/100\n",
      "2700/2700 [==============================] - 0s 59us/step - loss: 0.0209 - acc: 0.9930\n",
      "Epoch 35/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0601 - acc: 0.9841\n",
      "Epoch 36/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.1222 - acc: 0.9667\n",
      "Epoch 37/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.1631 - acc: 0.9622\n",
      "Epoch 38/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0707 - acc: 0.9781\n",
      "Epoch 39/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0390 - acc: 0.9870\n",
      "Epoch 40/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0277 - acc: 0.9919\n",
      "Epoch 41/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 42/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0198 - acc: 0.9948\n",
      "Epoch 43/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0184 - acc: 0.9948\n",
      "Epoch 44/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0164 - acc: 0.9956\n",
      "Epoch 45/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0149 - acc: 0.9959\n",
      "Epoch 46/100\n",
      "2700/2700 [==============================] - 0s 61us/step - loss: 0.0139 - acc: 0.9963\n",
      "Epoch 47/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0132 - acc: 0.9959\n",
      "Epoch 48/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0130 - acc: 0.9963\n",
      "Epoch 49/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0120 - acc: 0.9963\n",
      "Epoch 50/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0112 - acc: 0.9967\n",
      "Epoch 51/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0112 - acc: 0.9959\n",
      "Epoch 52/100\n",
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.0104 - acc: 0.9967\n",
      "Epoch 53/100\n",
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.0109 - acc: 0.9967\n",
      "Epoch 54/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0094 - acc: 0.9974\n",
      "Epoch 55/100\n",
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.0093 - acc: 0.9970\n",
      "Epoch 56/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0089 - acc: 0.9970\n",
      "Epoch 57/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.0084 - acc: 0.9970\n",
      "Epoch 58/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 59/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0084 - acc: 0.9970: 0s - loss: 0.0091 - acc: 0.996\n",
      "Epoch 60/100\n",
      "2700/2700 [==============================] - 0s 73us/step - loss: 0.0080 - acc: 0.9970\n",
      "Epoch 61/100\n",
      "2700/2700 [==============================] - 0s 59us/step - loss: 0.0086 - acc: 0.9970\n",
      "Epoch 62/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0075 - acc: 0.9974\n",
      "Epoch 63/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0066 - acc: 0.9974\n",
      "Epoch 64/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0062 - acc: 0.9974\n",
      "Epoch 65/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0059 - acc: 0.9974\n",
      "Epoch 66/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0057 - acc: 0.9974\n",
      "Epoch 67/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0053 - acc: 0.9974\n",
      "Epoch 68/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0053 - acc: 0.9974\n",
      "Epoch 69/100\n",
      "2700/2700 [==============================] - 0s 58us/step - loss: 0.0051 - acc: 0.9974\n",
      "Epoch 70/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0049 - acc: 0.9974\n",
      "Epoch 71/100\n",
      "2700/2700 [==============================] - 0s 58us/step - loss: 0.0047 - acc: 0.9974\n",
      "Epoch 72/100\n",
      "2700/2700 [==============================] - 0s 58us/step - loss: 0.0045 - acc: 0.9974\n",
      "Epoch 73/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0044 - acc: 0.9974\n",
      "Epoch 74/100\n",
      "2700/2700 [==============================] - 0s 60us/step - loss: 0.0045 - acc: 0.9974\n",
      "Epoch 75/100\n",
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.0046 - acc: 0.9970\n",
      "Epoch 76/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0042 - acc: 0.9974\n",
      "Epoch 77/100\n",
      "2700/2700 [==============================] - 0s 58us/step - loss: 0.0043 - acc: 0.9970\n",
      "Epoch 78/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0063 - acc: 0.9963\n",
      "Epoch 79/100\n",
      "2700/2700 [==============================] - 0s 58us/step - loss: 0.0183 - acc: 0.9941\n",
      "Epoch 80/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0650 - acc: 0.9870\n",
      "Epoch 81/100\n",
      "2700/2700 [==============================] - 0s 60us/step - loss: 0.1164 - acc: 0.9763\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.1055 - acc: 0.9785\n",
      "Epoch 83/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.0735 - acc: 0.9822\n",
      "Epoch 84/100\n",
      "2700/2700 [==============================] - 0s 54us/step - loss: 0.0507 - acc: 0.9859\n",
      "Epoch 85/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0171 - acc: 0.9944\n",
      "Epoch 86/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.0118 - acc: 0.9974\n",
      "Epoch 87/100\n",
      "2700/2700 [==============================] - 0s 52us/step - loss: 0.0106 - acc: 0.9963\n",
      "Epoch 88/100\n",
      "2700/2700 [==============================] - 0s 53us/step - loss: 0.0091 - acc: 0.9981\n",
      "Epoch 89/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 90/100\n",
      "2700/2700 [==============================] - 0s 55us/step - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 91/100\n",
      "2700/2700 [==============================] - 0s 63us/step - loss: 0.0065 - acc: 0.9989\n",
      "Epoch 92/100\n",
      "2700/2700 [==============================] - 0s 63us/step - loss: 0.0063 - acc: 0.9981\n",
      "Epoch 93/100\n",
      "2700/2700 [==============================] - 0s 61us/step - loss: 0.0059 - acc: 0.9989\n",
      "Epoch 94/100\n",
      "2700/2700 [==============================] - 0s 58us/step - loss: 0.0057 - acc: 0.9981\n",
      "Epoch 95/100\n",
      "2700/2700 [==============================] - 0s 56us/step - loss: 0.0058 - acc: 0.9981\n",
      "Epoch 96/100\n",
      "2700/2700 [==============================] - 0s 58us/step - loss: 0.0054 - acc: 0.9985\n",
      "Epoch 97/100\n",
      "2700/2700 [==============================] - 0s 74us/step - loss: 0.0058 - acc: 0.9981\n",
      "Epoch 98/100\n",
      "2700/2700 [==============================] - 0s 75us/step - loss: 0.0048 - acc: 0.9981\n",
      "Epoch 99/100\n",
      "2700/2700 [==============================] - 0s 60us/step - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 100/100\n",
      "2700/2700 [==============================] - 0s 57us/step - loss: 0.0051 - acc: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25567cb4c18>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train, batch_size = 100, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[163,   4],\n",
       "       [  6, 127]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 1482\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHMJJREFUeJzt3X+sJWddx/H3167t+gN3i3u1tbvuLaYYV6MtvcFFjLcKwrYh25gQ04qRKtqoqVp/b1PD3dYYKxgtJlVoEFGClIoIm6ZkNQiaGFt7q/xq68pSil1K7UUtRglC49c/ZqZ37uw58+Oc+fHMM59XcnPPmXnOnO8888x3nnlmzjnm7oiISFy+bOgARESkfUruIiIRUnIXEYmQkruISISU3EVEIqTkLiISISV3EZEIKbmLiERIyV1EJEK7hnrjffv2+erq6lBvLyIySg8++OBn3X2lqtxgyX11dZXNzc2h3l5EZJTM7FN1ymlYRkQkQkruIiIRUnIXEYmQkruISISU3EVEIlR5t4yZvQV4BfCUu3/bjPkGvAG4Cvg8cJ27/2PbgeZdcQU89ljyd8UVcN992/N2707+f+ELcMEFcN118MEPJmWyefn5AE8+CYcPJ8t78sntMocPJ8s/fjx57QUXwNNPJ6/dvTv5f/gwfOhDSfm9e5PXX3ABrK7ujCuL5a1vTZaRlc3Lx5fFWJx/4407l5HFky3/ttu21+uxx5LYb7vt7Lo5diypl2yds3Xbu3e7zq64Yud7FRXrIl8/WX3m6z+bf+ml2/V6/HjyHlldZMsq/s/qMB9rvn6ydYbtMsX6hZ3bq7j8/Pz8tN27k/dbXU3+srotboMq+fqfJduGt9++c/qsOHfvTuoxH0u+norbJnPsWPI/v30hWa+sLZRtg3lxZ9s128+K2+bpp5O2C9vrl5U5fHjnvjJPvv527z57H8rm33hj0uaz5/lys+oxe56Vv/TSpA3U2bb5HANJnd5++851y+Tb1bFjSdvvklX9EpOZfQ/w38CfzEnuVwE/Q5LcvxN4g7t/Z9Ubr62t+aK3Qpol/923H3epr/dpW+hxb2zALbcMHUU9odeljM+iP4JnZg+6+1pVucphGXf/W+A/SopcTZL43d3vA/aa2YX1Q5WpGktiFxmjNsbcLwIezz0/k047i5ldb2abZra5tbXVwluLiMgsbST3WSerM0843P1Od19z97WVlcpPz1bqesxKRGSs2kjuZ4ADuef7gSdaWG4lndaLiMzWRnI/AfyIJQ4Dn3P3z7Sw3LnW1+Hgwe3n5523/bdnT/J33nnJvI2N7TJ79iSPs/kHDyZ/WdnisoqvP3hw57Kz/9l75qcVl5XFm/+fn5+PPb+s4vyifDzFmIpxzCqfxZGtW75ei/EWp2XLzi8ze7y+vl1mfX3ne8J2vW5s7KyL4jKz//l5+e2Qn5ePaVb95svNWn5xHYqvya93fjsVy8/7y7fNebFl61ZcdvF12fxsXyjWU9n6zZPV2aw2XrZexfZQLJ/Fl5ePK2sfTeovH29xvbP3z8rPal/5ZRaXv76+c1+ou+7r6zvzRfZ+s7ZRVq5T7l76B7wD+AzwJZJe+muAnwR+Mp1vwB3AJ4CPAmtVy3R3Lr/8cl8WuG9slM/P/y8+ztvYOHtZ88rOW3b2+uQ6+PzXlMVcXNasZWxsJP/X13dOz5a/vl4eX/Z43vrl3yP/uuK0Yoyz6i9fLntcVg9ldV61rfPtoar+ypZT9r7Z+8yq32UV203Vssva8jz5bTCvLeXbcdXy8rHMK59f3qx2s4iytrNoG1q0/MbG7PqrG1NTwKbXyLGVBbr6ayu5l5m1ozfZuFU7ybwYqpL7MuY1lvxOUzf5lCX3bJlFTeqvLNZ5y1q0jopJu2rdypZTps4BalHFdlO17GXeO78OxXVeZN3mtfn88tpMcO7lB5GhzOsgKrk3UNbznFW2K/N6essmxqr3K+thlvWi6sTTVn1V9QDbPADOS1BNl1/3/btIIGUJsgtNtkudZfWd3Bc5c6ljmdfP68gouTdawfrJqcsdpu9eQtmOkp8XwoEvU9VDzFs0nrrbvO7ZXpWYknvd6VXLCjG5L9KelomzzTqd/x4TSO5153W5w/SRHPPqjFc3SRJ9JJMmyb3t96w7va3lL7vMPpN7m8MaxXHnvPz2b3sYq2r6ogeqRSm5t5Tcyy6alT0fs7oXkIfsgc57j5iSexcH9XyC7KrT0PQGhDYs0umYp+l1lVCSe1sXkpP3mEByr7sDx5Tcyyx6IaxrQyT3ugf+UHUVZ50z3rYPLLPutlpUncQdYnJfdrk7l1Mvuesrf3vW1adq88sN7ZO78+7p7eVe3wDec2zabj/Z8tpebojbMqiY6hwBuvjr8m6ZeVesQ9Blj6yNi0dd1lWf22EsPfR5huy5d6nNnnudMoteP+hC3z33yq/87coyX/mbMUsGZ4qy7wkP0byYh1pusa66iq9vY1+PIdpJH3W27HvUeX2+TYeUC9qq39a+8neMQtmYYzCvrorT69Sp6n3c+hhS6OM9Qh6i7NOok3tQ41uRKX4pW50vadMXubWnq7Zdttw+EuGy7zHmfb7v2Ec9LDNGoQ3LzFtOcXl1lh/SUEiXsYR0qi87TWHbTHpYJmRD9MimqMv60BlKuLRttim596yPWyGXMZaDRNX6xt57i4m2VTc0LBORNk9JQx+WGXIIKKThpxi0WZ9T2DYalpmgLk9J6/Tox9LrF5kCJXepRbdCiixmqP1CyV2kobGfocR8EA5x29xyyzB1rjH3EakaU5/S2GXo8fVlkessodVdaPG0zSz5396+qTH36PR5m1eIPaC80OPrSwy3/uV/TF3ao+QuM4V+6h56fFOy7Lb4m79pJQwpUHKXsyhxShMxnD3ESMl9ZPpIvNnOqiQvsryhhhAnndzHmLz67CWpRxYnXa/o1/Hjw9T5pJP72JKXdsruje2Av7HRPOaxrWMMdCtkz8Z4C1ZZzG19/cC8b4acgjGu89AxL/v+U/gmxzbpVsgJ0g4iQ1j2jFLtthtK7nIWDf9IE0rOYVJyH5k+f6ZMSf5sSmQyFpNO7nWSV2g7c5/xhLbuIRjbRfgq2sbxmnRyr9OwY9uZpdwYz1aWiTnm9j31A1etu2XM7AjwBuAc4M3uflth/jcCfwzsTcscc/d7y5YZwt0ydQx9J4KEJbb2ENv65MW6bq3dLWNm5wB3AFcCh4BrzexQodivAXe7+2XANcDvNw9ZRETaUmdY5oXAaXd/1N2/CNwFXF0o48DXpI/3AE+0F6KIiDRVJ7lfBDyee34mnZZ3HPhhMzsD3Av8TCvRiQRmjGPyspixj9nXSe42Y1pxJOta4K3uvh+4CnibmZ21bDO73sw2zWxza2urebQD0M4seWPf4YvUvucb+8XmOsn9DHAg93w/Zw+7vAa4G8Dd/x7YDewrLsjd73T3NXdfW1lZWSzinsW2M4vkxdy++z5whVaXdZL7A8AlZnaxmZ1LcsH0RKHMvwIvATCzbyFJ7uPomotIlPpOtqH19CuTu7s/A9wAnAQeIbkr5iEzu9XMjqbFfhH4CTP7MPAO4Dof6hvJRESk3oeY3P1ed3++u3+Tu/9GOu217n4iffywu7/Y3b/D3S9197/sMugmQjtVkp20fUS6Ef0nVEM7VZKdtH0kVGO/2Bx9chcRWcTYzyqV3EVEWhBaT1/JXUSkBWU9/SHOApTcRURyukjEQ1xbij651z1VGvv42liFdiorEstF/kn/QHZerF8PKiLNdJEL2lymfiBbRGTClNwjp+EmkWlSco9cLOOHImM2xLUlJXcRkZwuErFuhRyQ7toQEYhnKFPJPRXLBhURASX3zuhgIW1Se5KmlNw7EsqFTA03xaGL9qQDRtz0IaaO6ENR0qbQP1gj/dGHmGRQ6hWKDEvJXToRyrCUyFQpuYuIREjJvSNDX8jUsEhchm5PMj5K7h0ZOrm2PSzS9voMXT9j00V96YDRjlDbsu6WiVTTOyGOHy9vpE2XV1Ved2pILPpuy7pbRhppu6evXqHIsJTcpROhnqrWMebYRTJK7iIF885ilPSlTGjtQ8k9UhoWaV8bQ1ehJQBpT2if7VByj1TbSaTtg8VUDz6hJQBZXqhtWXfLCFB9t8yUzLv7oY27InSXULz62ra6W0YaUWIvp/qRsVFyFymYdZo91uEUHZSmS8ldpGBeQgx1bLXMWA9KYxRa+6iV3M3siJmdMrPTZnZsTpkfNLOHzewhM/vTdsMcF/WW4tTGdg0tAUh7QtvvK5O7mZ0D3AFcCRwCrjWzQ4UylwA3AS92928Fbuwg1tGIvbcUWiMeE9Wd9KVOz/2FwGl3f9TdvwjcBVxdKPMTwB3u/p8A7v5Uu2FKSGI/eInEoE5yvwh4PPf8TDot7/nA883s78zsPjM7MmtBZna9mW2a2ebW1tZiEYsMQMMpMjZ1krvNmFa8m3MXcAlwBXAt8GYz23vWi9zvdPc1d19bWVlpGqtM3JBDGmMdTtFBabrqJPczwIHc8/3AEzPKvNfdv+TunwROkSR7kdZoOKi5sR6UZHl1kvsDwCVmdrGZnQtcA5wolHkP8L0AZraPZJjm0TYDHRP1lqRrStpSpTK5u/szwA3ASeAR4G53f8jMbjWzo2mxk8C/m9nDwAeAX3b3f+8q6NDFvuPp4DU8ncVIFX23jIyGvpdlm+piuvTdMjXE3sMWkemadHLXqe24aDhIpL5JJ3cZF51pidSn5C4yQjGdxeig3Y1JX1DVRSmR4Wk/bEYXVEVEJmzSyT2mU1sRkbxJJ3eN9Yn0R/tbvyad3EWkP7r1uF9K7iIyKA2PdkPJXUQGpeGabii5y0K0Q8rQ1AbLTfo+d1mc7k2WptpuM1Ntg7rPXUSCorH1fim5i0gvNIzSLyV3EZEIKbmLiERIyV0WovFTGZraYDndLSMiMiK6W0ZEZMKU3EUmRnetTIOSu8jE6Au8pkHJXUQkQkruItIbDQn1R8ldRHqjIaH+KLmLiHrUEVJyF5mYWR/+UY86PkruIhNT7KWr1x4nJXeRiVOvPU5K7iIBib0Xre+D6U+t5G5mR8zslJmdNrNjJeVeaWZuZpXfeyAiZ4u9Fx37wSsklcndzM4B7gCuBA4B15rZoRnlngP8LHB/20GKSLfUo45PnZ77C4HT7v6ou38RuAu4eka5XwdeB3yhxfgkQuq9hUfbJD51kvtFwOO552fSac8ys8uAA+5+T4ux9U4NvB+xDz2MjXrtcaqT3G3GtGe/BN7Mvgz4XeAXKxdkdr2ZbZrZ5tbWVv0oe6KkI7Gb1YFRpyZOdZL7GeBA7vl+4Inc8+cA3wZ80MweAw4DJ2ZdVHX3O919zd3XVlZWFo9aJFJd96LVgZmOOsn9AeASM7vYzM4FrgFOZDPd/XPuvs/dV919FbgPOOru+pklkYbUi5a2VCZ3d38GuAE4CTwC3O3uD5nZrWZ2tOsAu6adSURiNPnfUDWDrAryj6U7x4/roDoUtfHx02+oLkB3DfRDiV2ke0ruOWNJOmOJU0SGo+Q+QrrjQUSqKLmLiOTEcmY8+eTe1zh7LA1GJHZNz4xD3bcnf7dMX9q8S0F3PMiidKdStab7V9/7o+6WEZGzKLFPh5L7COmWTRGpouQeoKre1dh7XxoaEOmextx70mRcLvYxdUu/ZzTmdZTxatr50Jj7xGkopT3q9UuXmravsn17yLaqnnuA1HOvfn3M9SPx6KKtqucuIjJhSu4ldPovImOl5F5iqO9wiX18fmMj/nUUGZrG3EtobDdM2i4yFhpzF2lAvX4ZiyHbqpK7nCX0aw2hxRdaPBKOIduGkntDU9iR9X3xzai+JERK7iVmnVKV7chTSPwSPrXDdixSjyHVvS6oNlR2gWRMF/rKPmI9pvUIQWj1FVo8Y7VIPfZR97qgKqU0lCASNyX3iQvpNFJE2qPkPnGzevC61bAZ1ZeESMm9oSnsyOrNN6P6khApuTdUtiP3kfiVSKTKFDogfVikHkOqe90tMzJtXY3P7pbRnRUi46K7ZaSUzgCWpzqUkCm5T1zXp5ExJ0DdTioh07DMyIxtGGVs8TYR87pJuDQsIyIzDXk2FfOZXGhqJXczO2Jmp8zstJkdmzH/F8zsYTP7iJm938wOth+qQFhX42WchhxO0lBWfyqTu5mdA9wBXAkcAq41s0OFYv8ErLn7twPvAl7XdqCSUM+nHapHiV2dnvsLgdPu/qi7fxG4C7g6X8DdP+Dun0+f3gfsbzdMidkQibZpD3JWjDqLkpDVSe4XAY/nnp9Jp83zGuB9s2aY2fVmtmlmm1tbW/WjlNGqkwDHcKo+K0b1/iVkdZK7zZg28x4BM/thYA14/az57n6nu6+5+9rKykr9KGW0lk2ASqAii6mT3M8AB3LP9wNPFAuZ2UuBm4Gj7v6/7YQnUzeGXv3YDDmcpKGs/lTe525mu4B/AV4CfBp4APghd38oV+YykgupR9z943XeWPe5S2aIH0Bpulzd0y6haO0+d3d/BrgBOAk8Atzt7g+Z2a1mdjQt9nrgq4E/M7MPmdmJJWIX6Zx6kBK7XXUKufu9wL2Faa/NPX5py3HJhAyRaJuO5etgIGOjT6jK4MZw0TSLcQyxioCSuwyoTqIMrcesC7zSxJCdAX1xmAxmjBcpxxizDKeL9qIvDgvcWE7vxxKniOyknvtAxtID7DLOsdRB3hhjluGo5y4ivdIZWfyU3CdGO/VyQrvAuyhdGI5f9MldyWynkHbqMSZKtSdpYsg2PvrkXrWzhZTMxqKvBKZEKbEbso2PPrmPNXmH3GvN12mXcSq5t0d1KUWjv1um6mq07m7YqU599FVn2jbt0RehTYfulpFRUI9zGCGfOUo7lNwrxJZ8QtupxzqsFpJF2mhs7VrOpmGZJZcfoz6HZWB69ds21eO0TGZYpqonGlpPdQzarDP1EEWGMfqee9em2HNvU1n9HT+eDMuofpdjlhyQdSCdhsn03CUsTRKMviO9PapDKVJyl1Y1vUC6saGLqiJdUHKvkB9/Vu+ofWOs09Bi1nWl4YTWFvI05t6Axt+rFesopA9NtWVs8Up3hmgLGnOXIKhXKTIMJfcSIZ9y1dFV/ItcNBWRfim5lxj7hb6u4i9b7iI9dfXuRdoXfXJXz7G+Yl319bH2pq/RNhWpFn1yb7P3GnMPM/tAUV6oZy5DxJU/oMTcDqSZkNtC9HfLLHM1e+x3RTSJf9b3k8x7/dD1MswdCuNuCxIP3S0jIjJhk0jui47RFk+5xjbW29UpY8inoiKSmMSwDLRzSh3zqXmTYZm2HD++2AFTwzJSZtF2NRYalkmF1MsMvcEV66pu3S26XoteGA1pmw4p9PY0lNBuBBhsO7l75R9wBDgFnAaOzZh/HvDOdP79wGrVMi+//HJvw8ZGdRlYbjnZvDrLWTaOocxb/zbqd9YyNjbCro8iqFcXfRpT/fWpWC919u1FbWzsXMas5bW9nYBNr5O3KwvAOcAngOcB5wIfBg4Vyvw08Mb08TXAO6uW20ZyP3iw3oYsK1OVuPNJqKxMVSPJlpOVWyaZ1rVnj/v6erP3KdZNnYY5q0z+fWfNTwY55se3qK4ScBZv1+q0pUwX9deFJuvUhuJ2Kttu+XmLxJm1i7I8MlRyrxxzN7MXAcfd/eXp85vSHv9v5sqcTMv8vZntAp4EVrxk4W2MudcdJy77Mqvscdltf9l71ClTFWudZbU1tlsWV533r3u9oqrO583PtDmW3dXYeF8/Zdfkfcby83p9x9nky+sWae/F12fm7ddtt8k2x9wvAh7PPT+TTptZxt2fAT4HfG29ULvX1hitxnpFZCzqJHebMa14HKpTBjO73sw2zWxza2urTnytaOuChi5gtUsHS+mC2lWiTnI/AxzIPd8PPDGvTDosswf4j+KC3P1Od19z97WVlZXFIpbgLLoz6WC5HCWx2dSuEnWS+wPAJWZ2sZmdS3LB9EShzAng1enjVwJ/XTbe3iYNuXSrTr1U7Uyx1G1o66EkVk/Zdlt2m25shNcuMruqCrj7M2Z2A3CS5M6Zt7j7Q2Z2K8lV2xPAHwJvM7PTJD32a7oMOnPw4NkNvE5F58tkj+ftKBsbcPvt9ZdXt8y817TZUPbsgUsvbfY+xbpZNIGsr28/nrWM7H3y5drQ5ady+0imTeNvu/66MHTyK9tuy34hXJ38M9T6R/8JVRGRmOgTqiIiE6bkLiISISV3EZEIKbmLiERIyV1EJEKD3S1jZlvApxZ8+T7gsy2G0wXFuLzQ44PwYww9PlCMTR1098pPgQ6W3JdhZpt1bgUakmJcXujxQfgxhh4fKMauaFhGRCRCSu4iIhEaa3K/c+gAalCMyws9Pgg/xtDjA8XYiVGOuYuISLmx9txFRKTE6JK7mR0xs1NmdtrMjg0UwwEz+4CZPWJmD5nZz6XTn2tmf2VmH0//n59ONzP7vTTmj5jZC3qM9Rwz+yczuyd9frGZ3Z/G+M70a5wxs/PS56fT+as9xLbXzN5lZv+c1uWLQqtDM/v5dBt/zMzeYWa7h65DM3uLmT1lZh/LTWtcb2b26rT8x83s1bPeq8X4Xp9u54+Y2V+Y2d7cvJvS+E6Z2ctz0zvb12fFmJv3S2bmZrYvfd57Hbaizg+thvJHjR/r7imOC4EXpI+fA/wLcAh4HXAsnX4M+K308VXA+0h+seowcH+Psf4C8KfAPenzu4Fr0sdvBH4qfdz4R85biO2PgR9PH58L7A2pDkl+PvKTwFfk6u66oesQ+B7gBcDHctMa1RvwXODR9P/56ePzO4zvZcCu9PFv5eI7lO7H5wEXp/v3OV3v67NiTKcfIPl6808B+4aqw1bWcegAGm6QFwEnc89vAm4KIK73At8PnAIuTKddCJxKH78JuDZX/tlyHce1H3g/8H3APWnj/GxuJ3u2PtMG/aL08a60nHUY29ekidMK04OpQ7Z/G/i5aZ3cA7w8hDoEVgvJs1G9AdcCb8pN31Gu7fgK834AeHv6eMc+nNVhH/v6rBiBdwHfATzGdnIfpA6X/RvbsEydH+vuVXrqfRlwP/D17v4ZgPT/16XFhor7duBXgP9Ln38t8LQnP2JejKPvHzl/HrAF/FE6bPRmM/sqAqpDd/808NvAvwKfIamTBwmnDvOa1tuQ+9KPkfSEKYmj9/jM7CjwaXf/cGFWMDE2MbbkXuuHuPtiZl8N/Dlwo7v/V1nRGdM6jdvMXgE85e4P1oyj7xh3kZwW/4G7Xwb8D8lwwjxD1OH5wNUkwwXfAHwVcGVJHEG1z9S8mAaJ1cxuBp4B3p5NmhNHr/GZ2VcCNwOvnTV7Tiwhbu9njS251/mx7l6Y2ZeTJPa3u/u708n/ZmYXpvMvBJ5Kpw8R94uBo2b2GHAXydDM7cBeS37EvBhHrR85b9EZ4Iy7358+fxdJsg+pDl8KfNLdt9z9S8C7ge8inDrMa1pvvddnesHxFcCrPB3HCCi+byI5iH843Wf2A/9oZhcEFGMjY0vudX6su3NmZiS/G/uIu/9Oblb+h8JfTTIWn03/kfSq+2Hgc9kpdFfc/SZ33+/uqyT19Nfu/irgAyQ/Yj4rxiz2zn/k3N2fBB43s29OJ70EeJiA6pBkOOawmX1lus2zGIOow4Km9XYSeJmZnZ+eobwsndYJMzsC/Cpw1N0/X4j7mvROo4uBS4B/oOd93d0/6u5f5+6r6T5zhuSmiScJpA4bG3rQf4GLIFeR3J3yCeDmgWL4bpLTr48AH0r/riIZX30/8PH0/3PT8gbckcb8UWCt53ivYPtumeeR7DyngT8Dzkun706fn07nP6+HuC4FNtN6fA/JHQdB1SFwC/DPwMeAt5Hc1TFoHQLvILkG8CWSJPSaReqNZOz7dPr3ox3Hd5pkfDrbX96YK39zGt8p4Mrc9M729VkxFuY/xvYF1d7rsI0/fUJVRCRCYxuWERGRGpTcRUQipOQuIhIhJXcRkQgpuYuIREjJXUQkQkruIiIRUnIXEYnQ/wP6eldBIjzBCwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zxc = np.array([x for x in bytes_from_file('y.raw')])\n",
    "asd = zxc.reshape((zxc.size//882,882),order = 'C')\n",
    "qwe = pd.DataFrame(asd)\n",
    "qwe = sc.transform(qwe)\n",
    "y_asd = classifier.predict(qwe)\n",
    "sum1 = 0\n",
    "sum0 = 0\n",
    "y_ASD = (y_asd>0.5)\n",
    "# print(y_ASD)\n",
    "for i in y_asd:\n",
    "    if(i == False):\n",
    "        sum0+=1\n",
    "    else:\n",
    "        sum1+=1\n",
    "print(sum0,sum1)\n",
    "\n",
    "plt.plot(y_asd,\"|b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
