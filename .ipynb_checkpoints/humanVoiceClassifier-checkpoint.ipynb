{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:38px;color:green\"><u>Human Voice classifier</u></div><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#importing data\n",
    "def bytes_from_file(filename, chunksize=8192):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunksize)\n",
    "            if chunk:\n",
    "                for b in chunk:\n",
    "                    yield b\n",
    "            else:\n",
    "                break\n",
    "def create_audio_data(l):\n",
    "    datArr = []\n",
    "    for i in l:\n",
    "        datArr.append(np.array([x for x in bytes_from_file(i)]))\n",
    "    datArr = np.concatenate(datArr)\n",
    "    datArr = datArr.reshape((datArr.size//882,882),order = 'C')\n",
    "    return pd.DataFrame(datArr),datArr.shape[0]\n",
    "\n",
    "def create_y_sequence(n_data,div):\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "    n = n_data//div  # check for float\n",
    "    l = []\n",
    "    for i in range(div):\n",
    "        l.append(np.ones(n)*i)\n",
    "    fet = pd.DataFrame(np.concatenate(l))\n",
    "    return onehotencoder.fit_transform(fet).toarray()\n",
    "\n",
    "\n",
    "# datArr1 = np.array([x for x in bytes_from_file('anuragD30.raw')])\n",
    "# datArr2 = np.array([x for x in bytes_from_file('anupamD30.raw')])\n",
    "\n",
    "# datArr = np.concatenate([datArr1,datArr2])\n",
    "\n",
    "# datArr = datArr.reshape((datArr.size//882,882),order = 'C')\n",
    "# datY = np.concatenate((np.zeros((1500),dtype = int),np.ones((1500),dtype = int)))\n",
    "x,size = create_audio_data(['anuragD30.raw','anupamD30.raw','animeshD30.raw','amanD30.raw','deepakbD30.raw'])\n",
    "print(size)\n",
    "y = create_y_sequence(size,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=882, units=80, kernel_initializer=\"uniform\")`\n",
      "  app.launch_new_instance()\n",
      "e:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=80, kernel_initializer=\"uniform\")`\n",
      "e:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=5, kernel_initializer=\"uniform\")`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 0)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# initializing ANN\n",
    "classifier = Sequential()\n",
    "# adding input and hidden layers\n",
    "classifier.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu', input_dim = 882))  # first hidded layer\n",
    "classifier.add(Dense(output_dim = 80, init = 'uniform', activation = 'relu'))  # second hidded layer\n",
    "classifier.add(Dense(output_dim = 5, init = 'uniform', activation = 'sigmoid'))  # output layer\n",
    "# compiling ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6750/6750 [==============================] - 1s 206us/step - loss: 0.5625 - acc: 0.7903\n",
      "Epoch 2/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.4505 - acc: 0.8140\n",
      "Epoch 3/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.3958 - acc: 0.8319\n",
      "Epoch 4/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.3625 - acc: 0.8432\n",
      "Epoch 5/100\n",
      "6750/6750 [==============================] - 0s 51us/step - loss: 0.3374 - acc: 0.8565\n",
      "Epoch 6/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.3179 - acc: 0.8676\n",
      "Epoch 7/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.3018 - acc: 0.8763\n",
      "Epoch 8/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.2858 - acc: 0.8833\n",
      "Epoch 9/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.2732 - acc: 0.8896\n",
      "Epoch 10/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.2576 - acc: 0.8988\n",
      "Epoch 11/100\n",
      "6750/6750 [==============================] - 0s 58us/step - loss: 0.2452 - acc: 0.9035\n",
      "Epoch 12/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.2340 - acc: 0.9068\n",
      "Epoch 13/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.2257 - acc: 0.9109\n",
      "Epoch 14/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.2169 - acc: 0.9159\n",
      "Epoch 15/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.2087 - acc: 0.9192\n",
      "Epoch 16/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.1956 - acc: 0.9252\n",
      "Epoch 17/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1898 - acc: 0.9275\n",
      "Epoch 18/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.1796 - acc: 0.9317\n",
      "Epoch 19/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.1733 - acc: 0.9349\n",
      "Epoch 20/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.1678 - acc: 0.9369\n",
      "Epoch 21/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1585 - acc: 0.9408\n",
      "Epoch 22/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1527 - acc: 0.9426\n",
      "Epoch 23/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.1499 - acc: 0.9436\n",
      "Epoch 24/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.1504 - acc: 0.9426\n",
      "Epoch 25/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1402 - acc: 0.9465\n",
      "Epoch 26/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1339 - acc: 0.9488\n",
      "Epoch 27/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1345 - acc: 0.9488\n",
      "Epoch 28/100\n",
      "6750/6750 [==============================] - 0s 58us/step - loss: 0.1335 - acc: 0.9495\n",
      "Epoch 29/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.1302 - acc: 0.9513\n",
      "Epoch 30/100\n",
      "6750/6750 [==============================] - 0s 62us/step - loss: 0.1232 - acc: 0.9537\n",
      "Epoch 31/100\n",
      "6750/6750 [==============================] - 0s 61us/step - loss: 0.1218 - acc: 0.9547\n",
      "Epoch 32/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.1218 - acc: 0.9540\n",
      "Epoch 33/100\n",
      "6750/6750 [==============================] - 0s 60us/step - loss: 0.1156 - acc: 0.9566\n",
      "Epoch 34/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.1125 - acc: 0.9581\n",
      "Epoch 35/100\n",
      "6750/6750 [==============================] - 0s 58us/step - loss: 0.1078 - acc: 0.9601\n",
      "Epoch 36/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.1121 - acc: 0.9584\n",
      "Epoch 37/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.1077 - acc: 0.9594\n",
      "Epoch 38/100\n",
      "6750/6750 [==============================] - 0s 73us/step - loss: 0.1087 - acc: 0.9595\n",
      "Epoch 39/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.1103 - acc: 0.9593\n",
      "Epoch 40/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0967 - acc: 0.9652\n",
      "Epoch 41/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0905 - acc: 0.9671\n",
      "Epoch 42/100\n",
      "6750/6750 [==============================] - 0s 61us/step - loss: 0.0892 - acc: 0.9669\n",
      "Epoch 43/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0875 - acc: 0.9679\n",
      "Epoch 44/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0921 - acc: 0.9665\n",
      "Epoch 45/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0919 - acc: 0.9663\n",
      "Epoch 46/100\n",
      "6750/6750 [==============================] - 0s 58us/step - loss: 0.0858 - acc: 0.9687\n",
      "Epoch 47/100\n",
      "6750/6750 [==============================] - 0s 62us/step - loss: 0.0840 - acc: 0.9682: 0s - loss: 0.0888 - acc: \n",
      "Epoch 48/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0860 - acc: 0.9679\n",
      "Epoch 49/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.1012 - acc: 0.9627\n",
      "Epoch 50/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.0886 - acc: 0.9675\n",
      "Epoch 51/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.0810 - acc: 0.9695\n",
      "Epoch 52/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.0815 - acc: 0.9705\n",
      "Epoch 53/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0901 - acc: 0.9668\n",
      "Epoch 54/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.0791 - acc: 0.9698\n",
      "Epoch 55/100\n",
      "6750/6750 [==============================] - 0s 60us/step - loss: 0.0709 - acc: 0.9734\n",
      "Epoch 56/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0648 - acc: 0.9763\n",
      "Epoch 57/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.0656 - acc: 0.9759\n",
      "Epoch 58/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.0636 - acc: 0.9771\n",
      "Epoch 59/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0645 - acc: 0.9768\n",
      "Epoch 60/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0798 - acc: 0.9712\n",
      "Epoch 61/100\n",
      "6750/6750 [==============================] - 0s 58us/step - loss: 0.0814 - acc: 0.9704\n",
      "Epoch 62/100\n",
      "6750/6750 [==============================] - 0s 61us/step - loss: 0.0751 - acc: 0.9720\n",
      "Epoch 63/100\n",
      "6750/6750 [==============================] - 0s 66us/step - loss: 0.0789 - acc: 0.9705\n",
      "Epoch 64/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0726 - acc: 0.9726\n",
      "Epoch 65/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.0668 - acc: 0.9747\n",
      "Epoch 66/100\n",
      "6750/6750 [==============================] - ETA: 0s - loss: 0.0651 - acc: 0.975 - 0s 62us/step - loss: 0.0652 - acc: 0.9756\n",
      "Epoch 67/100\n",
      "6750/6750 [==============================] - 0s 60us/step - loss: 0.0645 - acc: 0.9764\n",
      "Epoch 68/100\n",
      "6750/6750 [==============================] - 0s 60us/step - loss: 0.0602 - acc: 0.9778\n",
      "Epoch 69/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0548 - acc: 0.9808\n",
      "Epoch 70/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0514 - acc: 0.9817\n",
      "Epoch 71/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.0507 - acc: 0.9820\n",
      "Epoch 72/100\n",
      "6750/6750 [==============================] - 0s 64us/step - loss: 0.0491 - acc: 0.9822\n",
      "Epoch 73/100\n",
      "6750/6750 [==============================] - 0s 62us/step - loss: 0.0489 - acc: 0.9829\n",
      "Epoch 74/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.0507 - acc: 0.9816\n",
      "Epoch 75/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0482 - acc: 0.9832\n",
      "Epoch 76/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0640 - acc: 0.9770\n",
      "Epoch 77/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.1076 - acc: 0.9637\n",
      "Epoch 78/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0795 - acc: 0.9701\n",
      "Epoch 79/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0802 - acc: 0.9723\n",
      "Epoch 80/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0590 - acc: 0.9773\n",
      "Epoch 81/100\n",
      "6750/6750 [==============================] - 0s 56us/step - loss: 0.0510 - acc: 0.9816\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0446 - acc: 0.9841\n",
      "Epoch 83/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0427 - acc: 0.9850\n",
      "Epoch 84/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.0403 - acc: 0.9864\n",
      "Epoch 85/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0387 - acc: 0.9874\n",
      "Epoch 86/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0380 - acc: 0.9871\n",
      "Epoch 87/100\n",
      "6750/6750 [==============================] - 0s 51us/step - loss: 0.0371 - acc: 0.9877\n",
      "Epoch 88/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.0369 - acc: 0.9878\n",
      "Epoch 89/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.0366 - acc: 0.9876\n",
      "Epoch 90/100\n",
      "6750/6750 [==============================] - 0s 55us/step - loss: 0.0359 - acc: 0.9883\n",
      "Epoch 91/100\n",
      "6750/6750 [==============================] - 0s 65us/step - loss: 0.0348 - acc: 0.9886\n",
      "Epoch 92/100\n",
      "6750/6750 [==============================] - 0s 65us/step - loss: 0.0345 - acc: 0.9885\n",
      "Epoch 93/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.0396 - acc: 0.9864\n",
      "Epoch 94/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.0532 - acc: 0.9823\n",
      "Epoch 95/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1052 - acc: 0.9658\n",
      "Epoch 96/100\n",
      "6750/6750 [==============================] - 0s 53us/step - loss: 0.1214 - acc: 0.9613\n",
      "Epoch 97/100\n",
      "6750/6750 [==============================] - 0s 59us/step - loss: 0.0813 - acc: 0.9707\n",
      "Epoch 98/100\n",
      "6750/6750 [==============================] - 0s 57us/step - loss: 0.0574 - acc: 0.9802\n",
      "Epoch 99/100\n",
      "6750/6750 [==============================] - 0s 54us/step - loss: 0.0447 - acc: 0.9842\n",
      "Epoch 100/100\n",
      "6750/6750 [==============================] - 0s 52us/step - loss: 0.0413 - acc: 0.9856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd623c4dd8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train, batch_size = 100, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 619\n",
      "143 607\n",
      "117 633\n",
      "159 591\n",
      "159 591\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "for j in range(5):\n",
    "    cT = 0\n",
    "    cF = 0\n",
    "    for i in y_pred:\n",
    "        if i[j] == True:\n",
    "            cT+=1\n",
    "        else:\n",
    "            cF+=1\n",
    "    print(cT,cF)\n",
    "   78 942 95.33 87.33         \n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-c87ecf9ebcff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# print(y_ASD)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_asd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0msum0\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "zxc = np.array([x for x in bytes_from_file('x.raw')])\n",
    "asd = zxc.reshape((zxc.size//882,882),order = 'C')\n",
    "qwe = pd.DataFrame(asd)\n",
    "qwe = sc.transform(qwe)\n",
    "y_asd = classifier.predict(qwe)\n",
    "sum1 = 0\n",
    "sum0 = 0\n",
    "y_ASD = (y_asd>0.5)\n",
    "# print(y_ASD)\n",
    "for i in y_asd:\n",
    "    if(i == False):\n",
    "        sum0+=1\n",
    "    else:\n",
    "        sum1+=1\n",
    "print(sum0,sum1)\n",
    "\n",
    "plt.plot(y_asd,\"|b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
