{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:38px;color:green\"><u>Voice classifier</u></div><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Voice classifier</b> is <b>Artificial</b> Neural Network based classifier who's goal is to classify different voices or sound against provided labeled training dataset which consist of doctored <b>RAW audio</b> file.</li>\n",
    "<li>For training all RAW Audio files must be of same size preferably <b>atleast 30 second</b> duration</li>\n",
    "<li>RAW audio training data must not contain any <b>silence</b></li>\n",
    "<li>This model is trained and tested in <b>8-bit unsigned PCM</b> RAW audio format.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Format\n",
    "\n",
    "<ul>\n",
    "<li> RAW audio format is sampled at <b>44100H</b>z which means amplitude of sound wave is taken 44100 times every second.\n",
    "<li> Amplitude is divided into <b>256 parts</b> (in 8-bit PCM format) and stored in RAW audio file\n",
    "<li> \n",
    "</ul>\n",
    "    <i>NOTE: 44100Hz is chosen because if <b>nyquist rate</b> f<sub>c</sub> > 2f<sub>m</sub> where f<sub>m</sub> = 20,000Hz (max human hearable frequency)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working\n",
    "\n",
    "<ul>\n",
    "<li> Every voice (say human voice) have distinct <b>spectrum</b> of frequency of <b>harmonices (Hz)</b> and <b>loudness (dB)</b>\n",
    "<li> It is observed that around <b>1024 sample</b> is optimum for distinguishing several voices.\n",
    "<li> But because of sampling rate 44100Hz sample size should be multiple of 44100 because if we multiply \n",
    "    sample rate with time <i>t</i>. we get total sample which is divided to get total training set size which should be integer\n",
    "    <br/><i><b>(44100t)/n = total_tarining_set</b></i>\n",
    "<li> Nearest integer is <b>882</b>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum\n",
    "\n",
    "### CASE-1\n",
    "\n",
    "<img src = \"img/spec1.png\">\n",
    "\n",
    "### CASE-2\n",
    "\n",
    "<img src = \"img/spec2.png\">\n",
    "\n",
    "### CASE-3\n",
    "\n",
    "<img src = \"img/spec3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>https://singhroshan1999.github.io/voice-classifier/</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "INP_CONST = 882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_from_file(filename, chunksize=8192):\n",
    "    \"\"\" Read RAW Audio file and return generator function\n",
    "        Parameter(s): filename --> name of file to read\n",
    "                      chunksize --> number of bytes to read at a time\n",
    "        Returns: generator object\n",
    "    \"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunksize)\n",
    "            if chunk:\n",
    "                for b in chunk:\n",
    "                    yield b\n",
    "            else:\n",
    "                break\n",
    "def create_audio_data(l):\n",
    "    \"\"\"Reads list of RAW Audio file(s) and returns DataFrame\"\"\"\n",
    "    datArr = []\n",
    "    for i in l:\n",
    "        t_arr = np.array([x for x in bytes_from_file(i)])\n",
    "        datArr.append(t_arr[:t_arr.size - t_arr.size%INP_CONST])\n",
    "    datArr = np.concatenate(datArr)\n",
    "    datArr = datArr.reshape((datArr.size//INP_CONST,INP_CONST),order = 'C')\n",
    "    return pd.DataFrame(datArr),datArr.shape[0]\n",
    "\n",
    "def create_y_sequence(n_data,div):\n",
    "    \"\"\"Generate label for trainig\"\"\"\n",
    "    onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "    n = n_data//div  # check for float\n",
    "    l = []\n",
    "    for i in range(div):\n",
    "        l.append(np.ones(n)*i)\n",
    "    fet = pd.DataFrame(np.concatenate(l))\n",
    "    return onehotencoder.fit_transform(fet).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(x,y,units,batch_size = 100,epochs = 100,verbose = 0):\n",
    "    \"\"\"Train Artifitial Neural Networks\n",
    "    Parameter(s): x --> RAW audio data\n",
    "                  y --> Label\n",
    "                  units --> number of output of ANN\n",
    "                  batch_size --> size of batch (default = 100)\n",
    "                  epoch --> epoch (default = 100)\n",
    "                  verbose --> verbosity (default = 0) 0 --> none | 1 --> only epochs with progressbar | 2 --> only epoch\n",
    "    Return: tuple (classifier,sc) --> classifier --> keras model object\n",
    "                                      sc --> StandardScalar object\n",
    "    \"\"\"\n",
    "    sc = StandardScaler()\n",
    "    x = sc.fit_transform(x)\n",
    "    # initializing ANN\n",
    "    classifier = Sequential()\n",
    "    # adding input and hidden layers\n",
    "    classifier.add(Dense(units = 50,use_bias = True, kernel_initializer = 'random_normal', activation = 'relu', input_dim = INP_CONST))  # first hidded layer\n",
    "    classifier.add(Dense(units = 40,use_bias = True, kernel_initializer = 'random_normal', activation = 'relu'))  # second hidded layer\n",
    "    classifier.add(Dense(units = 30,use_bias = True, kernel_initializer = 'random_normal', activation = 'relu'))  # second hidded layer\n",
    "    classifier.add(Dense(units = 20,use_bias = True, kernel_initializer = 'random_normal', activation = 'relu'))  # second hidded layer\n",
    "    classifier.add(Dense(units = units,use_bias = True, kernel_initializer = 'random_normal', activation = 'sigmoid'))  # output layer\n",
    "    # compiling ANN\n",
    "    classifier.compile(optimizer = 'nadam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    classifier.fit(x, y, batch_size = batch_size, epochs = epochs,verbose = verbose)\n",
    "    return classifier,sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(file_list,name_list = [],verbose = 0,epochs = 100):\n",
    "    \"\"\"Train every file in file_list with name of each voice\n",
    "       Parameter(s): file_list --> list of file as on disk\n",
    "                     name_list --> list of corrorsponing name of voice\n",
    "       Return(s): (classifier,sc,name_list) --> classifier --> keras ANN model\n",
    "                                                sc --> StandardScalar object\n",
    "                                                name_list --> name_list\n",
    "    \"\"\"\n",
    "    x,size = create_audio_data(file_list)\n",
    "    y = create_y_sequence(size,5)\n",
    "    classifier = train_data(x,y,len(file_list),verbose = verbose,epochs = epochs)\n",
    "    return classifier[0],classifier[1],name_list\n",
    "\n",
    "\n",
    "train = train(['anuragD30.raw','anupamD30.raw','animeshD30.raw','amanD30.raw','deepakbD30.raw'],\n",
    "             ['anu','anup','ani','aman','dee'],verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0         1\n",
      "0   anu  0.757456\n",
      "1  anup  0.006656\n",
      "2   ani  0.005969\n",
      "3  aman  0.189908\n",
      "4   dee  0.041171\n",
      "      0         1\n",
      "0   anu  0.026449\n",
      "1  anup  0.686787\n",
      "2   ani  0.111648\n",
      "3  aman  0.034363\n",
      "4   dee  0.131642\n",
      "      0         1\n",
      "0   anu  0.038250\n",
      "1  anup  0.101881\n",
      "2   ani  0.560419\n",
      "3  aman  0.109841\n",
      "4   dee  0.171051\n",
      "      0         1\n",
      "0   anu  0.191873\n",
      "1  anup  0.044898\n",
      "2   ani  0.081464\n",
      "3  aman  0.506209\n",
      "4   dee  0.175246\n",
      "      0         1\n",
      "0   anu  0.042293\n",
      "1  anup  0.113324\n",
      "2   ani  0.174360\n",
      "3  aman  0.103249\n",
      "4   dee  0.552758\n"
     ]
    }
   ],
   "source": [
    "def predict(filename,classifier,scalar):\n",
    "    \"\"\"predict voice of given file\n",
    "       Parameter(s): filename --> as on disk\n",
    "                     classifier --> train() classifier\n",
    "                     scalar --> train() sc\n",
    "       Return(s): Datafram of predicted values and size tuple\"\"\"\n",
    "    df,size = create_audio_data([filename])\n",
    "    predicted_value = classifier.predict(scalar.transform(df))\n",
    "    return pd.DataFrame(predicted_value),size\n",
    "\n",
    "def predict_names(filename,train):\n",
    "    \"\"\"returns percent predicted values with name of voice\n",
    "       Parameter(s): filename --> as on disk\n",
    "                     train --> tuple returned by train()\n",
    "       Return(s): Dataframe of percent prediction and name\"\"\"\n",
    "    predicted,sum = predict(filename,train[0],train[1])\n",
    "    return pd.concat([pd.Series(train[2]),pd.Series([x/(sum) for x in  predicted.sum()])],axis = 1)\n",
    "print(predict_names('x.raw',train))\n",
    "print(predict_names('y.raw',train))\n",
    "print(predict_names('an.raw',train))\n",
    "print(predict_names('am.raw',train))\n",
    "print(predict_names('dee.raw',train))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
